{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b69d95",
   "metadata": {},
   "source": [
    "This code is to calculate the window diagnostics for Wind and Precipitation from WRF output. And compare with the wrfdly output. This is to try and validate the output from WRF.\n",
    "\n",
    "## Data needed\n",
    "* wrfout: output at each time step including t0. (i.e. `write_hist_at_0h_rst = .true.`)\n",
    "* wrfdly: output for the diagnostics every hour (i.e. `auxhist7_interval = 60`). Must cover the same time period as the wrfout file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe78d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61e30cf-832f-4ecd-9262-7ababc1ff972",
   "metadata": {},
   "source": [
    "# Paths to data and averaging windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9fe12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_path=Path(\"/scratch/w35/ccc561/jenkins/workspace/WRF/WRF-CCRC/jenkins-tests/jan00-diagnostics\")\n",
    "wrfout_file=\"wrfout_d01_2000-01-24_12:00:00\"\n",
    "wrfdly_file=\"wrfdly_d01_2000-01-24_12:00:00\"\n",
    "\n",
    "# Time windows to calculate values on\n",
    "Window_ave = pd.to_timedelta([\"00:05:00\",\"00:10:00\",\"00:20:00\",\"00:30:00\",\"00:60:00\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdd82f1-6f2e-492a-9a39-8bd5aacd6b96",
   "metadata": {},
   "source": [
    "# Functions\n",
    "### Functions to wrangle the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa070e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windspeed(out_d01):\n",
    "    U10_wrfout = out_d01[\"U10\"][1:]\n",
    "    V10_wrfout = out_d01[\"V10\"][1:]\n",
    "    Speed = xr.ufuncs.sqrt(U10_wrfout**2+V10_wrfout**2)\n",
    "    Speed.attrs[\"units\"]=U10_wrfout.attrs[\"units\"]\n",
    "    Speed.attrs[\"description\"]=\"Wind speed at 10m\"\n",
    "    Speed = Speed.rename(\"Wind speed\")\n",
    "    \n",
    "    return Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3773f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(Speed, timestep):\n",
    "    Wind_dist = Speed * timestep/np.timedelta64(1,\"s\")\n",
    "    Wind_dist.attrs[\"units\"]=\"m\"\n",
    "    Wind_dist.attrs[\"description\"]=\"Distance travelled by wind\"\n",
    "    Wind_dist = Wind_dist.rename(\"Wind distance\")\n",
    "    \n",
    "    return Wind_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9d59d9-3712-40e1-8f38-56bd69c9a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_hour_coord(diag):\n",
    "    hour = diag[\"Time\"].dt.hour\n",
    "    diag_hour = diag.rename({\"Time\":\"hour\"})\n",
    "    diag_hour = diag_hour.assign_coords({\"hour\":('hour',hour)})\n",
    "    \n",
    "    return diag_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649fdff0-f21f-4ac7-b809-9637af98cb6c",
   "metadata": {},
   "source": [
    "### Functions to get the average window values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83f60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_per_window(ntstep_in_window):\n",
    "    '''Get the weigths for the weighted average.\n",
    "    If ntstep_in_window has no decimal part:\n",
    "        the number of weights is the integer part of ntstep_in_window and all weights are 1.\n",
    "    If ntstep_in_window has a decimal part:\n",
    "        we need one more weight compared to the previous case. This weight is equal to the decimal part.\n",
    "        \n",
    "    ntstep_in_window: list of floats, number of timesteps in each averaging window'''\n",
    "    \n",
    "    weights=[]\n",
    "    for ww in ntstep_in_window:\n",
    "        int_part = np.floor(ww).astype(np.int_)\n",
    "        decimal_last_weight = ww - int_part\n",
    "        nweights = int_part + (decimal_last_weight > 0)\n",
    "        # All weights are 1 but the last\n",
    "        window_weights=[1] * int_part\n",
    "        window_weights.append(decimal_last_weight)\n",
    "        # Remove the last weight if there is no decimal part\n",
    "        window_weights = window_weights[:nweights]\n",
    "        # Convert to DataArray\n",
    "        window_weights = xr.DataArray(window_weights,dims=\"weights\",name=\"weights\")\n",
    "        weights.append(window_weights)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c3bd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_windows(Dist, rolling_window):\n",
    "    '''Construct the rolling windows and remove the first one that contains NaN'''\n",
    "    # Construct the windows\n",
    "    Wind_dist_window=Dist.rolling(Time=rolling_window).construct(window_dim=\"weights\")\n",
    "    # First window starts with NaN\n",
    "    Wind_dist_window=Wind_dist_window[1:]\n",
    "    \n",
    "    # Need to change the XTIME labels. Xarray gives the labels at the end or the centre of the rolling window but we need the data at the start.\n",
    "    XTIME = Wind_dist_window[\"XTIME\"]\n",
    "    XTIME_ts = XTIME[1]-XTIME[0]\n",
    "    XTIME = XTIME - XTIME_ts\n",
    "    \n",
    "    Wind_dist_window = Wind_dist_window.assign_coords({\"XTIME\":('Time',XTIME)})\n",
    "    \n",
    "    return Wind_dist_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b22ef8a-4807-45da-8f9b-447b4930fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_weighted_average(data_on_window, weights, average_window):\n",
    "    '''Get the average quantity, per second,  for each rolling window.\n",
    "    We want the time at the end of each rolling window so we add 1 hour to the time coordinate XTIME\n",
    "    \n",
    "    data_on_window: DataArray with a \"weights\" dimension, output from get_rolling_windows\n",
    "    weights: list of floats, weights to apply to each value of data_on_window along the \"weights\" dimension\n",
    "    average_window: Pandas timedelta, length of the window in time'''\n",
    "\n",
    "    data_window_weighted=data_on_window.weighted(weights).sum(dim=\"weights\")/average_window.seconds\n",
    "    \n",
    "    onehour = pd.to_timedelta([\"01:00:00\"])\n",
    "    data_window_weighted.coords[\"XTIME\"] = data_window_weighted.coords[\"XTIME\"] + onehour[0]\n",
    "    \n",
    "    return data_window_weighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30e24cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_valuemax(data_weighted):\n",
    "    '''Get the max of the average quantity over rolling windows within 1 hour.\n",
    "    The time of data_weighted is assumed to be the start of the \n",
    "    \n",
    "    data_weighted: DataArray with a \"XTIME\" coordinate for the time and a \"Time\" dimension'''\n",
    "\n",
    "    wind_window_max = Wind_window_weighted.groupby(\"XTIME.hour\").max(dim=\"Time\")\n",
    "    wind_window_max = wind_window_max.rename(\"wind_window_max\")\n",
    "    \n",
    "    return wind_window_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "795770e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_of_max(val_array):\n",
    "    '''Replaces argmax which does not exist for DataArrayGroupBy objects'''\n",
    "    ind_max = val_array.argmax(dim=\"Time\")\n",
    "    return ind_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c978ab1-57bc-4714-9640-318dca995bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_timeofmax(data_weighted):\n",
    "    '''Get the time of the max of the average quantity over rolling windows within 1 hour\n",
    "    The time of the max is given at the beginning of the rolling window.\n",
    "    \n",
    "    data_weighted: DataArray with a \"XTIME\" coordinate for the time and a \"Time\" dimension'''\n",
    "\n",
    "    time_window_max = Wind_window_weighted.groupby(\"XTIME.hour\").apply(index_of_max)\n",
    "    time_window_max = time_window_max.rename(\"time_window_max\")\n",
    "    \n",
    "    return time_window_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed4c20-adea-4889-9f3d-d24e1098a477",
   "metadata": {},
   "source": [
    "# Start program\n",
    "## Read in wrfout and wrfdly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8c42136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in data for domain 1\n",
    "out_d01=xr.open_dataset(data_path/wrfout_file)\n",
    "dly_d01=xr.open_dataset(data_path/wrfdly_file)\n",
    "\n",
    "# Decode the times and add as the XTIME coordinate to the dataset\n",
    "times = [tt.item().decode() for tt in dly_d01[\"Times\"]]\n",
    "dly_time=xr.DataArray(pd.to_datetime(times,format=\"%Y-%m-%d_%H:%M:%S\"),dims=[\"Time\"],name=\"Time\",coords={})\n",
    "dly_d01=dly_d01.assign_coords({\"Time\":(\"Time\",dly_time)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a2a417-2ae7-463c-898b-68700658d110",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate timestep from wrfout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8283f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wrfout timestep. It should be the time step of the run\n",
    "timestep = out_d01[\"XTIME\"][1]-out_d01[\"XTIME\"][0]\n",
    "timestep = pd.to_timedelta(timestep.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4bb0ce-c9a7-458e-be32-8693ef50a793",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the diagnostic and time from wrfdly. And the distance travelled by the wind from wrfout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6334532e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select the first point only\n",
    "The first time step of the diagnostics and the wrfout is the initial conditions so we need to remove it (`Time=slice(1,-1)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "994dee04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UV10MAX5=dly_d01[\"UV10MAX5\"].isel(south_north=0,west_east=0,Time=slice(1,-1))\n",
    "TUV10MAX5 = dly_d01[\"TUV10MAX5\"].isel(south_north=0,west_east=0,Time=slice(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee367cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Speed = get_windspeed(out_d01).isel(south_north=0, west_east=0)#,Time=slice(1,-1))\n",
    "Dist  = get_distance(Speed, timestep)  # Speed is already selected, no need to select Dist as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c28e17",
   "metadata": {},
   "source": [
    "## Calculate the average windows and weights for each window\n",
    "We need to know how many timesteps we need to average over for each window. For this, we divide the Window period by the timestep, in float, then take the `ceil()` to round up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b59e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of time steps in in each window.\n",
    "ntstep_in_window = Window_ave/timestep\n",
    "rolling_windows = [np.ceil(nt).astype(np.int_) for nt in ntstep_in_window]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c33bd7",
   "metadata": {},
   "source": [
    "For each window, define a scaling factor to apply to each time step for the weighting average.\n",
    "\n",
    "For example, if ntstep_in_window = 1.6666, we need to average 2 timesteps with the weights (1, 0.66666)\n",
    "\n",
    "* If ntstep_in_window has no decimal part, the number of weights is the integer part of ntstep_in_window and all weights are 1.\n",
    "* If ntstep_in_window has a decimal part, we need one more weight compared to the previous case. This weight is equal to the decimal part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef6966ff-b88e-4059-8bb7-b4a5e2510abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_weights_per_window(ntstep_in_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee14f265",
   "metadata": {},
   "source": [
    "## Get the frequency of the wrfdly outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e794803d",
   "metadata": {},
   "source": [
    "## Test on the first window\n",
    "1. Construct the windows for the distance\n",
    "2. Add the weights and calculate the sum over each window\n",
    "3. For each hour, get the max. value and the time of the max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41fbd627-f113-4d02-ae29-30cdd69ac39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wind_dist_window = get_rolling_windows(Dist, rolling_windows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9ff2d23-e7f6-45fb-9b2f-238cdb17a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wind_window_weighted = window_weighted_average(Wind_dist_window, weights[0], Window_ave[0])\n",
    "wind_window_max = window_valuemax(Wind_window_weighted)\n",
    "time_window_max = window_timeofmax(Wind_window_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23694545-c418-4a45-8b2c-80e6fb5e1c2d",
   "metadata": {},
   "source": [
    "We need to change the Time coordinate of UV10MAX5 and TUV10MAX5 to be just the hour as it is the time coordinate of the window arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61e3c02b-7ee2-422c-8ffd-3c7dbae1078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "UV10MAX5_hour = convert_to_hour_coord(UV10MAX5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb3693bf-d92c-491b-a109-8f4dc8ceaea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_comp = xr.merge([wind_window_max, UV10MAX5_hour], join=\"inner\")\n",
    "np.allclose(ds_comp['wind_window_max'].data, ds_comp['UV10MAX5'].data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5235e729b48b8850374e5c6ce911b34baf708643e8dde4db9e493874d0cef443"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
